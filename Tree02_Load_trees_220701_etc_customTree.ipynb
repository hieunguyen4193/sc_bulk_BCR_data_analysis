{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hieunguyen/miniconda3/envs/ete3_py39/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trees: 13481\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from typing import List, Union, Optional, Callable\n",
    "import pickle\n",
    "from Bio import AlignIO, SeqIO\n",
    "from ete3 import Tree, TreeNode\n",
    "from gctree import CollapsedTree\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import umap\n",
    "from ete3 import Tree, faces, TreeStyle, NodeStyle, TextFace, SequenceFace, COLOR_SCHEMES, CircleFace\n",
    "from GCTree_preparation import *\n",
    "import warnings\n",
    "import math\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "path_to_storage = \"/media/hieunguyen/HNSD01/storage/all_BSimons_datasets\"\n",
    "outdir = \"/media/hieunguyen/HNSD_mini/outdir/sc_bulk_BCR_data_analysis_v0.1\"\n",
    "\n",
    "PROJECT = \"220701_etc_biopsies\"\n",
    "path_to_main_output = f\"{outdir}/tree_analysis/{PROJECT}\"\n",
    "path_to_02_output = os.path.join(path_to_main_output, \"02_output\")\n",
    "os.system(f\"mkdir -p {path_to_02_output}\")\n",
    "\n",
    "output_type = \"custom_group_output\"\n",
    "\n",
    "path_to_trees = os.path.join(path_to_storage, PROJECT, \"GCtrees/v0.2\", output_type)\n",
    "\n",
    "all_tree_folder = [item for item in pathlib.Path(path_to_trees).glob(\"*\") if \n",
    "                   os.path.isfile(f\"{str(item)}/02_dnapars/gctree.out.inference.1.nk\") == True]\n",
    "\n",
    "all_nk_files = [item for item in pathlib.Path(path_to_trees).glob(\"*/*/*gctree.out.inference.1.nk\")]  \n",
    "print(f\"Number of trees: {len(all_tree_folder)}\")   \n",
    "\n",
    "path_to_metadata = \"/media/hieunguyen/HNSD01/src/sc_bulk_BCR_data_analysis/preprocessing/220701_etc_biopsies/metadata.csv\"\n",
    "mid_metadata = pd.read_csv(path_to_metadata, sep =\";\")\n",
    "path_to_04_output = os.path.join(outdir, \"VDJ_output\", \"04_output\")\n",
    "thres = 0.85\n",
    "\n",
    "all_clone_files = list(pathlib.Path(outdir).glob(f\"VDJ_output/*/VDJ_output_{thres}/preprocessed_files/clonesets*.split_clones.xlsx\"))\n",
    "\n",
    "clonedf = pd.read_csv(os.path.join(path_to_04_output, \"full_clonedf_with_mutation_rate.csv\"), index_col= [0])\n",
    "clonedf = clonedf[clonedf['num_mutation'] != \"region_not_covered-skip\"]\n",
    "clonedf = clonedf[clonedf['dataset.name'] == \"220701_etc_biopsies\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the tree data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####------------------------------------------------------------------------#####\n",
    "##### GENERATE TREE SUMMARY DATA FRAME\n",
    "#####------------------------------------------------------------------------#####\n",
    "rerun = True\n",
    "if (os.path.isfile(f\"{path_to_02_output}/tree_summarydf.csv\") == False) or (rerun == True):\n",
    "    saveTreeobj = dict()\n",
    "    # loop through all trees\n",
    "    maindf = pd.DataFrame()\n",
    "    # for treedir in tqdm(all_tree_folder[0:1]):\n",
    "    for treedir in tqdm(all_tree_folder):\n",
    "        cloneid = treedir.name\n",
    "        treedir = str(treedir)\n",
    "\n",
    "        mouseID = cloneid.split(\"_\")[0]\n",
    "        group = \"_\".join(cloneid.split(\"_\")[1:3]).replace(\"biopsy_YFP\", \"biopsy\")\n",
    "        V_gene = cloneid.split(\"_\")[3]\n",
    "        J_gene = cloneid.split(\"_\")[4]\n",
    "        CDR3_len = cloneid.split(\"_\")[5]\n",
    "\n",
    "        nk_path = f\"{treedir}/02_dnapars/gctree.out.inference.1.nk\"\n",
    "        ab_dict_path = os.path.join(treedir, \"01_deduplicate\", f\"{cloneid}.abundance.csv\")\n",
    "        path_to_orig_fasta= f\"{treedir}/01_deduplicate/{cloneid}.aln.fasta\"\n",
    "        input_idmaps = f\"{treedir}/01_deduplicate/{cloneid}.id_map_seq.csv\"\n",
    "    \n",
    "        treeobj = GCtree(\n",
    "            nk_path = nk_path,\n",
    "            ab_dict_path = ab_dict_path,\n",
    "            origin_fasta = path_to_orig_fasta,\n",
    "            idmap_seq = input_idmaps\n",
    "        )\n",
    "        \n",
    "        saveTreeobj[cloneid] = treeobj\n",
    "        seqdf_orig = treeobj.seqdf\n",
    "        seqs = treeobj.seqs\n",
    "        num_nodes = len(treeobj.nodes)\n",
    "        num_leaves = len(treeobj.leaves)\n",
    "        num_internal_nodes = len(treeobj.internal_nodes)\n",
    "        num_passthrough_nodes = len(treeobj.passthrough_nodes)\n",
    "        num_split_nodes = len(treeobj.split_nodes)\n",
    "        num_observed_nodes = len(treeobj.observed_nodes)\n",
    "        num_inferred_nodes = len(treeobj.inferred_nodes)\n",
    "        count_single_node = treeobj.count_single_node\n",
    "        count_mix_node = treeobj.count_mix_node\n",
    "\n",
    "        all_MIDs = seqdf_orig[\"MID\"].unique()\n",
    "        all_groups = [mid_metadata[mid_metadata[\"Unnamed: 0\"] == item][\"population\"].unique()[0] for item in all_MIDs]\n",
    "        tmpdf = pd.DataFrame(\n",
    "            {\n",
    "                \"cloneid\": cloneid,\n",
    "                \"mouseID\": mouseID,\n",
    "                \"group\": group,\n",
    "                \"V_gene\": V_gene,\n",
    "                \"J_gene\": J_gene,\n",
    "                \"CDR3_len\": CDR3_len,\n",
    "                \"num_nodes\": num_nodes,\n",
    "                \"num_leaves\": num_leaves,\n",
    "                \"num_internal_nodes\": num_internal_nodes,\n",
    "                \"num_passthrough_nodes\": num_passthrough_nodes,\n",
    "                \"num_split_nodes\": num_split_nodes,\n",
    "                \"num_observed_nodes\": num_observed_nodes,\n",
    "                \"num_inferred_nodes\": num_inferred_nodes,\n",
    "                \"num_MID\": len(all_MIDs),\n",
    "                \"available_population\": \",\".join(all_groups),\n",
    "                \"num_seq_fasta\": len(seqs),\n",
    "                \"num_single_node\": count_single_node,\n",
    "                \"num_mix_node\": count_mix_node\n",
    "            },\n",
    "            index=[0],\n",
    "        )\n",
    "        maindf = pd.concat([maindf, tmpdf], axis = 0)\n",
    "    maindf = maindf.sort_values(by = \"num_MID\", ascending = False)\n",
    "\n",
    "    maindf.to_csv(f\"{path_to_02_output}/tree_summarydf.csv\", index = False)\n",
    "    # Save the dictionary to a pickle file\n",
    "    with open(f\"{path_to_02_output}/saveTreeobj.pkl\", \"wb\") as f:\n",
    "        pickle.dump(saveTreeobj, f)\n",
    "else:\n",
    "    maindf = pd.read_csv(f\"{path_to_02_output}/tree_summarydf.csv\")\n",
    "    # Reload the dictionary from the pickle file\n",
    "    with open(f\"{path_to_02_output}/saveTreeobj.pkl\", \"rb\") as f:\n",
    "        saveTreeobj = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize some trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'saveTreeobj' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# cloneid = \"m12_all_YFP_IGHV1-18-01_IGHJ3-01_36_2\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m color_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./hex_color.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cloneid \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[43msaveTreeobj\u001b[49m\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[1;32m      4\u001b[0m     mouseid \u001b[38;5;241m=\u001b[39m cloneid\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m     group \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(cloneid\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m3\u001b[39m])\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbiopsy_YFP\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbiopsy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'saveTreeobj' is not defined"
     ]
    }
   ],
   "source": [
    "# cloneid = \"m12_all_YFP_IGHV1-18-01_IGHJ3-01_36_2\"\n",
    "color_path = \"./hex_color.csv\"\n",
    "for cloneid in tqdm(saveTreeobj.keys()):\n",
    "    mouseid = cloneid.split(\"_\")[0]\n",
    "    group = \"_\".join(cloneid.split(\"_\")[1:3]).replace(\"biopsy_YFP\", \"biopsy\")\n",
    "    path_to_save_tree_svg = os.path.join(path_to_02_output, mouseid, group)\n",
    "    os.system(f\"mkdir -p {path_to_save_tree_svg}\")\n",
    "\n",
    "    treeobj = saveTreeobj[cloneid] \n",
    "    avai_mids = treeobj.seqdf[\"MID\"].unique()\n",
    "    mid_color_pal = pd.read_csv(color_path, index_col = [0]).to_dict()[\"hex color\"]\n",
    "\n",
    "    ts = treeobj.generate_tree_style(color_path = color_path)\n",
    "    treeobj.tree.render(\"%%inline\", tree_style=ts) \n",
    "\n",
    "    for input_mid in avai_mids:\n",
    "        input_mid_col = mid_color_pal[input_mid]\n",
    "        ts.legend.add_face(CircleFace(10, input_mid_col), column = 0)\n",
    "        ts.legend.add_face(TextFace(input_mid), column = 0)\n",
    "\n",
    "    _ = treeobj.tree.render(f\"{path_to_save_tree_svg}/{cloneid}.svg\", tree_style=ts) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maindf_mixtree = maindf[(maindf['num_mix_node'] > 0)]\n",
    "# maindf_mixtree.available_population.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mouseid = \"m11\"\n",
    "# yfp_case = \"all\"\n",
    "\n",
    "# path_to_tree_fasta = f\"{outdir}/VDJ_output/05_output/220701_etc_biopsies/FASTA/{mouseid}/{yfp_case}\"\n",
    "# mouse_mids = mid_metadata[mid_metadata[\"mouse\"] == mouseid][\"Unnamed: 0\"].unique()\n",
    "\n",
    "# ##### list of biopsy samples from the given mouse, MID\n",
    "# biopsy_samples = mid_metadata[(mid_metadata[\"mouse\"] == mouseid) & (mid_metadata[\"population\"] == \"biopsy\")][\"Unnamed: 0\"].unique()\n",
    "\n",
    "# ##### summary information of all trees obtained from the given mouse\n",
    "# tree_mousedf = maindf[maindf[\"mouseID\"] == mouseid]\n",
    "\n",
    "# ##### list of all clones from all samples of the given mouse\n",
    "# clone_mousedf = clonedf[clonedf[\"id\"].isin(mouse_mids)]    \n",
    "\n",
    "# ##### list of all clones from the biopsy sample of the given mouse\n",
    "# other_clone_mousedf = clone_mousedf[clone_mousedf[\"id\"].isin(biopsy_samples) == False]\n",
    "# biopsy_clone_mousedf = clone_mousedf[clone_mousedf[\"id\"].isin(biopsy_samples)]\n",
    "\n",
    "# tree_mousedf.group.unique()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ete3_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
