{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hieunguyen/miniconda3/envs/ete3_py39/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trees: 7618\n"
     ]
    }
   ],
   "source": [
    "#####--------------------------------------------------------------------#####\n",
    "##### PREPARATION\n",
    "#####--------------------------------------------------------------------#####\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from typing import List, Union, Optional, Callable\n",
    "import pickle\n",
    "from Bio import AlignIO, SeqIO\n",
    "from ete3 import Tree, TreeNode\n",
    "from gctree import CollapsedTree\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import umap\n",
    "from ete3 import Tree, faces, TreeStyle, NodeStyle, TextFace, SequenceFace, COLOR_SCHEMES, CircleFace\n",
    "from GCTree_preparation import *\n",
    "import warnings\n",
    "import math\n",
    "from matplotlib.patches import Rectangle\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "path_to_storage = \"/media/hieunguyen/HNHD01/storage/all_BSimons_datasets\"\n",
    "outdir = \"/media/hieunguyen/GSHD_HN01/outdir/sc_bulk_BCR_data_analysis_v0.1\"\n",
    "\n",
    "PROJECT = \"220701_etc_biopsies\"\n",
    "path_to_main_output = f\"{outdir}/tree_analysis/{PROJECT}\"\n",
    "path_to_01_output = os.path.join(path_to_main_output, \"01_output\")\n",
    "path_to_08_output = os.path.join(path_to_main_output, \"08_output\")\n",
    "os.system(f\"mkdir -p {path_to_08_output}\")\n",
    "\n",
    "output_type = \"mouse_based_output\"\n",
    "\n",
    "path_to_trees = os.path.join(path_to_storage, PROJECT, \"GCtrees/v0.2\", output_type)\n",
    "\n",
    "all_tree_folder = [item for item in pathlib.Path(path_to_trees).glob(\"*\") if \n",
    "                   os.path.isfile(f\"{str(item)}/02_dnapars/gctree.out.inference.1.nk\") == True]\n",
    "\n",
    "all_nk_files = [item for item in pathlib.Path(path_to_trees).glob(\"*/*/*gctree.out.inference.1.nk\")]  \n",
    "print(f\"Number of trees: {len(all_tree_folder)}\")   \n",
    "\n",
    "path_to_metadata = \"/media/hieunguyen/HNSD01/src/sc_bulk_BCR_data_analysis/preprocessing/220701_etc_biopsies/metadata.csv\"\n",
    "mid_metadata = pd.read_csv(path_to_metadata, sep =\";\")\n",
    "mid_metadata = mid_metadata.drop(['Unnamed: 6', 'Unnamed: 7'], axis = 1)\n",
    "mid_metadata.columns = ['MID', 'mouse', 'age', 'day', 'population', 'label', 'hex color']\n",
    "\n",
    "##### Re run the summary analysis of all trees and rendering tree figures\n",
    "# rerun = True\n",
    "rerun = False\n",
    "\n",
    "path_to_04_output = os.path.join(outdir, \"VDJ_output\", \"04_output\")\n",
    "thres = 0.85\n",
    "\n",
    "clonedf = pd.read_csv(os.path.join(path_to_04_output, \"full_clonedf_with_mutation_rate.csv\"), index_col= [0])\n",
    "clonedf = clonedf[clonedf['num_mutation'] != \"region_not_covered-skip\"]\n",
    "clonedf = clonedf[clonedf['dataset.name'] == \"220701_etc_biopsies\"]\n",
    "\n",
    "maindf = pd.read_csv(f\"{path_to_01_output}/tree_summarydf.csv\")\n",
    "\n",
    "def get_tree_sum_abundance(x):\n",
    "    mouseid = x.split(\"_\")[0]\n",
    "    path_to_save_tree_svg = os.path.join(path_to_01_output, mouseid)\n",
    "    os.system(f\"mkdir -p {path_to_save_tree_svg}\")\n",
    "\n",
    "    treeobj = saveTreeobj[x] \n",
    "\n",
    "    idmapdf = treeobj.idmapseqdf.copy()\n",
    "    seqdf = treeobj.seqdf.copy()\n",
    "    seqdf[\"population\"] = seqdf[\"MID\"].apply(lambda x: mid_metadata[mid_metadata[\"MID\"] == x][\"population\"].values[0])\n",
    "    seqdf = seqdf.merge(idmapdf, right_on = \"seq\", left_on = \"seq\")\n",
    "    abd = seqdf.abundance.sum()\n",
    "    return abd\n",
    "\n",
    "tqdm.pandas()\n",
    "# Reload the dictionary from the pickle file\n",
    "with open(f\"{path_to_01_output}/saveTreeobj.pkl\", \"rb\") as f:\n",
    "    saveTreeobj = pickle.load(f)\n",
    "if os.path.isfile(f\"{path_to_01_output}/tree_summarydf.addedAbundance.csv\") == False:\n",
    "    maindf[\"clone_sum_abundance\"] = maindf[\"cloneid\"].progress_apply(lambda x: get_tree_sum_abundance(x))\n",
    "    maindf[\"pct_sum_abundance\"] = maindf[[\"clone_sum_abundance\", \"mouseID\"]].progress_apply(lambda x: x[0]/maindf[maindf[\"mouseID\"] == x[1]][\"clone_sum_abundance\"].sum(), axis = 1)\n",
    "    maindf = maindf.sort_values(by=  \"pct_sum_abundance\", ascending = False)\n",
    "    maindf.to_csv(f\"{path_to_01_output}/tree_summarydf.addedAbundance.csv\", index=False)\n",
    "else:\n",
    "    maindf = pd.read_csv(f\"{path_to_01_output}/tree_summarydf.addedAbundance.csv\")\n",
    "color_path = \"./hex_color.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### analysis example for 1 tree. \n",
    "# cloneid = \"m30_IGHV1-82-01_IGHJ2-01_30_1.aln\"\n",
    "\n",
    "# mouseid = cloneid.split(\"_\")[0]\n",
    "# path_to_save_tree_svg = os.path.join(path_to_01_output, mouseid)\n",
    "# os.system(f\"mkdir -p {path_to_save_tree_svg}\")\n",
    "\n",
    "# treeobj = saveTreeobj[cloneid] \n",
    "# avai_mids = treeobj.seqdf[\"MID\"].unique()\n",
    "# mid_color_pal = pd.read_csv(color_path, index_col = [0]).to_dict()[\"hex color\"]\n",
    "\n",
    "# ts = treeobj.generate_tree_style(color_path = color_path)\n",
    "# # treeobj.tree.render(\"%%inline\", tree_style=ts) \n",
    "\n",
    "# for input_mid in avai_mids:\n",
    "#     if input_mid == \"GL\":\n",
    "#         input_mid_col = \"gray\"\n",
    "#     else:\n",
    "#         input_mid_col = mid_color_pal[input_mid]\n",
    "#     ts.legend.add_face(CircleFace(10, input_mid_col), column = 0)\n",
    "#     ts.legend.add_face(TextFace(input_mid), column = 0)\n",
    "\n",
    "# idmapdf = treeobj.idmapseqdf.copy()\n",
    "# seqdf = treeobj.seqdf.copy()\n",
    "# seqdf[\"population\"] = seqdf[\"MID\"].apply(lambda x: mid_metadata[mid_metadata[\"Unnamed: 0\"] == x][\"population\"].values[0])\n",
    "# seqdf = seqdf.merge(idmapdf, right_on = \"seq\", left_on = \"seq\")\n",
    "# treeobj.tree.render(f\"%%inline\", tree_style=ts) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 59/7618 [00:02<04:59, 25.28it/s]"
     ]
    }
   ],
   "source": [
    "#####-------------------------------------------------------------#####\n",
    "##### Generate nodedf: summary all features of nodes\n",
    "#####-------------------------------------------------------------#####\n",
    "if os.path.isfile(os.path.join(path_to_08_output, \"nodedf.csv\")) == False:\n",
    "    nodedf = pd.DataFrame()\n",
    "    for cloneid in tqdm(saveTreeobj.keys()):\n",
    "        mouseid = cloneid.split(\"_\")[0]\n",
    "        path_to_save_tree_svg = os.path.join(path_to_01_output, mouseid)\n",
    "        os.system(f\"mkdir -p {path_to_save_tree_svg}\")\n",
    "\n",
    "        treeobj = saveTreeobj[cloneid] \n",
    "\n",
    "        idmapdf = treeobj.idmapseqdf.copy()\n",
    "        seqdf = treeobj.seqdf.copy()\n",
    "        seqdf[\"population\"] = seqdf[\"MID\"].apply(lambda x: mid_metadata[mid_metadata[\"MID\"] == x][\"population\"].values[0])\n",
    "        seqdf = seqdf.merge(idmapdf, right_on = \"seq\", left_on = \"seq\")\n",
    "\n",
    "        df = pd.DataFrame(data = seqdf.seqid.unique(), columns = [\"seqid\"])\n",
    "        df[\"mouseid\"] = mouseid\n",
    "        df[\"cloneID\"] = cloneid\n",
    "        df[\"population\"] = df[\"seqid\"].apply(lambda x: \",\".join(seqdf[seqdf[\"seqid\"] == x][\"population\"].values) \n",
    "                                            if len(seqdf[seqdf[\"seqid\"] == x][\"population\"].unique()) > 1 else seqdf[seqdf[\"seqid\"] == x][\"population\"].values[0])\n",
    "        df[\"abundance\"] = df[\"seqid\"].apply(lambda x: seqdf[seqdf[\"seqid\"] == x][\"abundance\"].sum())\n",
    "        df[\"MID\"] = df[\"seqid\"].apply(lambda x: \",\".join(seqdf[seqdf[\"seqid\"] == x][\"MID\"].values) \n",
    "                                            if len(seqdf[seqdf[\"seqid\"] == x][\"MID\"].unique()) > 1 else seqdf[seqdf[\"seqid\"] == x][\"MID\"].values[0])\n",
    "        df[\"mixed_node\"] = df[\"population\"].apply(lambda x: \"yes\" if \",\" in x else \"no\")\n",
    "\n",
    "        df[\"dist_to_root\"] = df[\"seqid\"].apply(lambda x: treeobj.node_depth(node = [item for item in treeobj.nodes if item.name == x][0], topo = False))\n",
    "        df[\"topo_dist_to_root\"] = df[\"seqid\"].apply(lambda x: treeobj.node_depth(node = [item for item in treeobj.nodes if item.name == x][0], topo = True))\n",
    "\n",
    "        deepest_node = df[df[\"dist_to_root\"] == df[\"dist_to_root\"].max()].seqid.unique()[0]\n",
    "\n",
    "        df[\"dist_to_deepest\"] = df[\"seqid\"].apply(lambda x: treeobj.tree.get_distance(x, deepest_node) if x != deepest_node else 0)\n",
    "        df[\"topo_dist_to_deepest\"] = df[\"seqid\"].apply(lambda x: treeobj.tree.get_distance(x, deepest_node, topology_only= True) if x != deepest_node else 0)\n",
    "\n",
    "        # heatmap_plotdf = df[[\"seqid\",'population', \"mixed_node\", 'dist_to_root', 'dist_to_deepest']]\n",
    "        # heatmap_plotdf[\"population\"] = heatmap_plotdf[[\"population\", \"mixed_node\", \"seqid\"]].apply(lambda x: \"_\".join(x), axis = 1)\n",
    "        # heatmap_plotdf = heatmap_plotdf.drop([\"mixed_node\", \"seqid\"], axis = 1).set_index(\"population\")\n",
    "        # plt.figure(figsize= (10, 15))\n",
    "        # sns.heatmap(heatmap_plotdf, cmap=\"coolwarm\", cbar=-1, linewidths=0.5, linecolor='black')\n",
    "        # for tick_label in plt.gca().get_yticklabels():\n",
    "        #     tick_text = tick_label.get_text()\n",
    "        #     if \"yes\" in tick_text:\n",
    "        #         tick_label.set_color('red')\n",
    "        #     elif \"biopsy\" in tick_text:\n",
    "        #         tick_label.set_color('blue')\n",
    "        #     else:\n",
    "        #         tick_label.set_color('black')\n",
    "                \n",
    "        df[\"population2\"] = df[\"population\"].apply(lambda x: \"biopsy\" if x == \"biopsy\" else \"other\")\n",
    "        min_val = dict()\n",
    "        max_val = dict()\n",
    "        mean_val = dict()\n",
    "\n",
    "        for dist_type in [\"dist_to_root\", \"dist_to_deepest\"]:\n",
    "            min_val[dist_type] = dict()\n",
    "            max_val[dist_type] = dict()\n",
    "            mean_val[dist_type] = dict()\n",
    "            for group in df.population2.unique():\n",
    "                min_val[dist_type][group] = df.groupby(\"population2\")[dist_type].min()[group]\n",
    "                max_val[dist_type][group] = df.groupby(\"population2\")[dist_type].max()[group]\n",
    "                mean_val[dist_type][group] = df.groupby(\"population2\")[dist_type].mean()[group]\n",
    "        df[\"parent_node\"] = df[\"seqid\"].apply(lambda x: treeobj.tree.search_nodes(name=x)[0].up.name)\n",
    "\n",
    "        df[\"parent_node_type\"] = df[\"parent_node\"].apply(lambda x: seqdf[seqdf[\"seqid\"] == x][\"population\"].values[0] if x in seqdf[\"seqid\"].values else \"inferred_node\")\n",
    "        nodedf = pd.concat([nodedf, df], axis = 0)\n",
    "    nodedf.to_csv(os.path.join(path_to_08_output, \"nodedf.csv\"), index = False)\n",
    "else:\n",
    "    nodedf = pd.read_csv(os.path.join(path_to_08_output, \"nodedf.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, numpy.int64 found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabundance\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseqid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseqdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mseqdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseqid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mabundance\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mseqdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mseqdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseqid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mabundance\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mseqdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mseqdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseqid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mabundance\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ete3_py39/lib/python3.9/site-packages/pandas/core/series.py:4917\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ete3_py39/lib/python3.9/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ete3_py39/lib/python3.9/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/miniconda3/envs/ete3_py39/lib/python3.9/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ete3_py39/lib/python3.9/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabundance\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseqid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseqdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mseqdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseqid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mabundance\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m                                     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(seqdf[seqdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseqid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m x][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabundance\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munique()) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m seqdf[seqdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseqid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m x][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabundance\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, numpy.int64 found"
     ]
    }
   ],
   "source": [
    "df[\"abundance\"] = df[\"seqid\"].apply(lambda x: \",\".join(seqdf[seqdf[\"seqid\"] == x][\"abundance\"].values)\n",
    "                                    if len(seqdf[seqdf[\"seqid\"] == x][\"abundance\"].unique()) > 1 else seqdf[seqdf[\"seqid\"] == x][\"abundance\"].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seqid</th>\n",
       "      <th>mouseid</th>\n",
       "      <th>cloneID</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seq1</td>\n",
       "      <td>m43</td>\n",
       "      <td>m43_IGHV3-6-01_IGHJ2-01_42_2.aln</td>\n",
       "      <td>Ly6c+YFP-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seq2</td>\n",
       "      <td>m43</td>\n",
       "      <td>m43_IGHV3-6-01_IGHJ2-01_42_2.aln</td>\n",
       "      <td>Ly6c+YFP-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seq3</td>\n",
       "      <td>m43</td>\n",
       "      <td>m43_IGHV3-6-01_IGHJ2-01_42_2.aln</td>\n",
       "      <td>Ly6c+YFP-,Ly6c-YFP-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  seqid mouseid                           cloneID           population\n",
       "0  seq1     m43  m43_IGHV3-6-01_IGHJ2-01_42_2.aln            Ly6c+YFP-\n",
       "1  seq2     m43  m43_IGHV3-6-01_IGHJ2-01_42_2.aln            Ly6c+YFP-\n",
       "2  seq3     m43  m43_IGHV3-6-01_IGHJ2-01_42_2.aln  Ly6c+YFP-,Ly6c-YFP-"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ete3_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
