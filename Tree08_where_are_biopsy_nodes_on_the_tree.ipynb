{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hieunguyen/miniconda3/envs/ete3_py39/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trees: 7618\n"
     ]
    }
   ],
   "source": [
    "#####--------------------------------------------------------------------#####\n",
    "##### PREPARATION\n",
    "#####--------------------------------------------------------------------#####\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from typing import List, Union, Optional, Callable\n",
    "import pickle\n",
    "from Bio import AlignIO, SeqIO\n",
    "from ete3 import Tree, TreeNode\n",
    "from gctree import CollapsedTree\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import umap\n",
    "from ete3 import Tree, faces, TreeStyle, NodeStyle, TextFace, SequenceFace, COLOR_SCHEMES, CircleFace\n",
    "from GCTree_preparation import *\n",
    "import warnings\n",
    "import math\n",
    "from matplotlib.patches import Rectangle\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "tqdm.pandas()\n",
    "from collections import Counter\n",
    "\n",
    "path_to_storage = \"/media/hieunguyen/HNHD01/storage/all_BSimons_datasets\"\n",
    "outdir = \"/media/hieunguyen/GSHD_HN01/outdir/sc_bulk_BCR_data_analysis_v0.1\"\n",
    "\n",
    "PROJECT = \"220701_etc_biopsies\"\n",
    "path_to_main_output = f\"{outdir}/tree_analysis/{PROJECT}\"\n",
    "path_to_01_output = os.path.join(path_to_main_output, \"01_output\")\n",
    "path_to_08_output = os.path.join(path_to_main_output, \"08_output\")\n",
    "os.system(f\"mkdir -p {path_to_08_output}\")\n",
    "\n",
    "output_type = \"mouse_based_output\"\n",
    "\n",
    "path_to_trees = os.path.join(path_to_storage, PROJECT, \"GCtrees/v0.2\", output_type)\n",
    "\n",
    "all_tree_folder = [item for item in pathlib.Path(path_to_trees).glob(\"*\") if \n",
    "                   os.path.isfile(f\"{str(item)}/02_dnapars/gctree.out.inference.1.nk\") == True]\n",
    "\n",
    "all_nk_files = [item for item in pathlib.Path(path_to_trees).glob(\"*/*/*gctree.out.inference.1.nk\")]  \n",
    "print(f\"Number of trees: {len(all_tree_folder)}\")   \n",
    "\n",
    "path_to_metadata = \"/media/hieunguyen/HNSD01/src/sc_bulk_BCR_data_analysis/preprocessing/220701_etc_biopsies/metadata.csv\"\n",
    "mid_metadata = pd.read_csv(path_to_metadata, sep =\";\")\n",
    "mid_metadata = mid_metadata.drop(['Unnamed: 6', 'Unnamed: 7'], axis = 1)\n",
    "mid_metadata.columns = ['MID', 'mouse', 'age', 'day', 'population', 'label', 'hex color']\n",
    "\n",
    "##### Re run the summary analysis of all trees and rendering tree figures\n",
    "# rerun = True\n",
    "rerun = False\n",
    "\n",
    "path_to_04_output = os.path.join(outdir, \"VDJ_output\", \"04_output\")\n",
    "thres = 0.85\n",
    "\n",
    "clonedf = pd.read_csv(os.path.join(path_to_04_output, \"full_clonedf_with_mutation_rate.csv\"), index_col= [0])\n",
    "clonedf = clonedf[clonedf['num_mutation'] != \"region_not_covered-skip\"]\n",
    "clonedf = clonedf[clonedf['dataset.name'] == \"220701_etc_biopsies\"]\n",
    "\n",
    "maindf = pd.read_csv(f\"{path_to_01_output}/tree_summarydf.csv\")\n",
    "\n",
    "def get_tree_sum_abundance(x):\n",
    "    mouseid = x.split(\"_\")[0]\n",
    "    path_to_save_tree_svg = os.path.join(path_to_01_output, mouseid)\n",
    "    os.system(f\"mkdir -p {path_to_save_tree_svg}\")\n",
    "\n",
    "    treeobj = saveTreeobj[x] \n",
    "\n",
    "    idmapdf = treeobj.idmapseqdf.copy()\n",
    "    seqdf = treeobj.seqdf.copy()\n",
    "    seqdf[\"population\"] = seqdf[\"MID\"].apply(lambda x: mid_metadata[mid_metadata[\"MID\"] == x][\"population\"].values[0])\n",
    "    seqdf = seqdf.merge(idmapdf, right_on = \"seq\", left_on = \"seq\")\n",
    "    abd = seqdf.abundance.sum()\n",
    "    return abd\n",
    "\n",
    "tqdm.pandas()\n",
    "# Reload the dictionary from the pickle file\n",
    "with open(f\"{path_to_01_output}/saveTreeobj.pkl\", \"rb\") as f:\n",
    "    saveTreeobj = pickle.load(f)\n",
    "if os.path.isfile(f\"{path_to_01_output}/tree_summarydf.addedAbundance.csv\") == False:\n",
    "    maindf[\"clone_sum_abundance\"] = maindf[\"cloneid\"].progress_apply(lambda x: get_tree_sum_abundance(x))\n",
    "    maindf[\"pct_sum_abundance\"] = maindf[[\"clone_sum_abundance\", \"mouseID\"]].progress_apply(lambda x: x[0]/maindf[maindf[\"mouseID\"] == x[1]][\"clone_sum_abundance\"].sum(), axis = 1)\n",
    "    maindf = maindf.sort_values(by=  \"pct_sum_abundance\", ascending = False)\n",
    "    maindf.to_csv(f\"{path_to_01_output}/tree_summarydf.addedAbundance.csv\", index=False)\n",
    "else:\n",
    "    maindf = pd.read_csv(f\"{path_to_01_output}/tree_summarydf.addedAbundance.csv\")\n",
    "color_path = \"./hex_color.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### analysis example for 1 tree. \n",
    "# cloneid = \"m30_IGHV1-82-01_IGHJ2-01_30_1.aln\"\n",
    "\n",
    "# mouseid = cloneid.split(\"_\")[0]\n",
    "# path_to_save_tree_svg = os.path.join(path_to_01_output, mouseid)\n",
    "# os.system(f\"mkdir -p {path_to_save_tree_svg}\")\n",
    "\n",
    "# treeobj = saveTreeobj[cloneid] \n",
    "# avai_mids = treeobj.seqdf[\"MID\"].unique()\n",
    "# mid_color_pal = pd.read_csv(color_path, index_col = [0]).to_dict()[\"hex color\"]\n",
    "\n",
    "# ts = treeobj.generate_tree_style(color_path = color_path)\n",
    "# # treeobj.tree.render(\"%%inline\", tree_style=ts) \n",
    "\n",
    "# for input_mid in avai_mids:\n",
    "#     if input_mid == \"GL\":\n",
    "#         input_mid_col = \"gray\"\n",
    "#     else:\n",
    "#         input_mid_col = mid_color_pal[input_mid]\n",
    "#     ts.legend.add_face(CircleFace(10, input_mid_col), column = 0)\n",
    "#     ts.legend.add_face(TextFace(input_mid), column = 0)\n",
    "\n",
    "# idmapdf = treeobj.idmapseqdf.copy()\n",
    "# seqdf = treeobj.seqdf.copy()\n",
    "# seqdf[\"population\"] = seqdf[\"MID\"].apply(lambda x: mid_metadata[mid_metadata[\"Unnamed: 0\"] == x][\"population\"].values[0])\n",
    "# seqdf = seqdf.merge(idmapdf, right_on = \"seq\", left_on = \"seq\")\n",
    "# treeobj.tree.render(f\"%%inline\", tree_style=ts) \n",
    "\n",
    "def plot_tree_inline(cloneid):\n",
    "    mouseid = cloneid.split(\"_\")[0]\n",
    "    path_to_save_tree_svg = os.path.join(path_to_01_output, mouseid)\n",
    "    os.system(f\"mkdir -p {path_to_save_tree_svg}\")\n",
    "\n",
    "    treeobj = saveTreeobj[cloneid] \n",
    "    avai_mids = treeobj.seqdf[\"MID\"].unique()\n",
    "    mid_color_pal = pd.read_csv(color_path, index_col = [0]).to_dict()[\"hex color\"]\n",
    "\n",
    "    ts = treeobj.generate_tree_style(color_path = color_path)\n",
    "    # treeobj.tree.render(\"%%inline\", tree_style=ts) \n",
    "\n",
    "    for input_mid in avai_mids:\n",
    "        if input_mid == \"GL\":\n",
    "            input_mid_col = \"gray\"\n",
    "        else:\n",
    "            input_mid_col = mid_color_pal[input_mid]\n",
    "        ts.legend.add_face(CircleFace(10, input_mid_col), column = 0)\n",
    "        ts.legend.add_face(TextFace(input_mid), column = 0)\n",
    "\n",
    "    idmapdf = treeobj.idmapseqdf.copy()\n",
    "    seqdf = treeobj.seqdf.copy()\n",
    "    seqdf[\"population\"] = seqdf[\"MID\"].apply(lambda x: mid_metadata[mid_metadata[\"MID\"] == x][\"population\"].values[0])\n",
    "    seqdf = seqdf.merge(idmapdf, right_on = \"seq\", left_on = \"seq\")\n",
    "    # treeobj.tree.render(f\"%%inline\", tree_style=ts) \n",
    "    # plt.show()\n",
    "    return treeobj, ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "population_combinations = []\n",
    "for i in range(1, len(mid_metadata.population.unique()) + 1):\n",
    "    population_combinations.extend(combinations(mid_metadata.population.unique(), i))\n",
    "all_populations = [\",\".join(item) for item in population_combinations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7618/7618 [58:52<00:00,  2.16it/s]   \n"
     ]
    }
   ],
   "source": [
    "#####-------------------------------------------------------------#####\n",
    "##### Generate nodedf: summary all features of nodes\n",
    "#####-------------------------------------------------------------#####\n",
    "if os.path.isfile(os.path.join(path_to_08_output, \"nodedf.csv\")) == False:\n",
    "    '''\n",
    "    Help on method get_distance in module ete3.coretype.tree:\n",
    "    get_distance(target, target2=None, topology_only=False) method of ete3.coretype.tree.TreeNode instance\n",
    "        Returns the distance between two nodes. If only one target is\n",
    "        specified, it returns the distance between the target and the\n",
    "        current node.\n",
    "        \n",
    "        :argument target: a node within the same tree structure.\n",
    "        \n",
    "        :argument target2: a node within the same tree structure. If\n",
    "        not specified, current node is used as target2.\n",
    "        \n",
    "        :argument False topology_only: If set to True, distance will\n",
    "        refer to the number of nodes between target and target2.\n",
    "        \n",
    "        :returns: branch length distance between target and\n",
    "        target2. If topology_only flag is True, returns the number\n",
    "        of nodes between target and target2.\n",
    "    '''\n",
    "    nodedf = pd.DataFrame()\n",
    "    all_trees = list(saveTreeobj.keys())\n",
    "    for cloneid in tqdm(all_trees):\n",
    "        mouseid = cloneid.split(\"_\")[0]\n",
    "        path_to_save_tree_svg = os.path.join(path_to_01_output, mouseid)\n",
    "        os.system(f\"mkdir -p {path_to_save_tree_svg}\")\n",
    "\n",
    "        treeobj = saveTreeobj[cloneid] \n",
    "\n",
    "        idmapdf = treeobj.idmapseqdf.copy()\n",
    "        seqdf = treeobj.seqdf.copy()\n",
    "        seqdf[\"population\"] = seqdf[\"MID\"].apply(lambda x: mid_metadata[mid_metadata[\"MID\"] == x][\"population\"].values[0])\n",
    "        seqdf = seqdf.merge(idmapdf, right_on = \"seq\", left_on = \"seq\")\n",
    "\n",
    "        df = pd.DataFrame(data = seqdf.seqid.unique(), columns = [\"seqid\"])\n",
    "        df[\"mouseid\"] = mouseid\n",
    "        df[\"cloneID\"] = cloneid\n",
    "        df[\"population\"] = df[\"seqid\"].apply(lambda x: \",\".join(seqdf[seqdf[\"seqid\"] == x][\"population\"].unique()) \n",
    "                                            if len(seqdf[seqdf[\"seqid\"] == x][\"population\"].unique()) > 1 else seqdf[seqdf[\"seqid\"] == x][\"population\"].values[0])\n",
    "        df[\"abundance\"] = df[\"seqid\"].apply(lambda x: seqdf[seqdf[\"seqid\"] == x][\"abundance\"].sum())\n",
    "        df[\"MID\"] = df[\"seqid\"].apply(lambda x: \",\".join(seqdf[seqdf[\"seqid\"] == x][\"MID\"].values) \n",
    "                                            if len(seqdf[seqdf[\"seqid\"] == x][\"MID\"].unique()) > 1 else seqdf[seqdf[\"seqid\"] == x][\"MID\"].values[0])\n",
    "        df[\"mixed_node\"] = df[\"population\"].apply(lambda x: \"yes\" if \",\" in x else \"no\")\n",
    "\n",
    "        df[\"dist_to_root\"] = df[\"seqid\"].apply(lambda x: treeobj.node_depth(node = [item for item in treeobj.nodes if item.name == x][0], topo = False))\n",
    "        df[\"topo_dist_to_root\"] = df[\"seqid\"].apply(lambda x: treeobj.node_depth(node = [item for item in treeobj.nodes if item.name == x][0], topo = True))\n",
    "\n",
    "        deepest_node = df[df[\"dist_to_root\"] == df[\"dist_to_root\"].max()].seqid.unique()[0]\n",
    "\n",
    "        df[\"dist_to_deepest\"] = df[\"seqid\"].apply(lambda x: treeobj.tree.get_distance(x, deepest_node) if x != deepest_node else 0)\n",
    "        df[\"topo_dist_to_deepest\"] = df[\"seqid\"].apply(lambda x: treeobj.tree.get_distance(x, deepest_node, topology_only= True) if x != deepest_node else 0)\n",
    "\n",
    "        # heatmap_plotdf = df[[\"seqid\",'population', \"mixed_node\", 'dist_to_root', 'dist_to_deepest']]\n",
    "        # heatmap_plotdf[\"population\"] = heatmap_plotdf[[\"population\", \"mixed_node\", \"seqid\"]].apply(lambda x: \"_\".join(x), axis = 1)\n",
    "        # heatmap_plotdf = heatmap_plotdf.drop([\"mixed_node\", \"seqid\"], axis = 1).set_index(\"population\")\n",
    "        # plt.figure(figsize= (10, 15))\n",
    "        # sns.heatmap(heatmap_plotdf, cmap=\"coolwarm\", cbar=-1, linewidths=0.5, linecolor='black')\n",
    "        # for tick_label in plt.gca().get_yticklabels():\n",
    "        #     tick_text = tick_label.get_text()\n",
    "        #     if \"yes\" in tick_text:\n",
    "        #         tick_label.set_color('red')\n",
    "        #     elif \"biopsy\" in tick_text:\n",
    "        #         tick_label.set_color('blue')\n",
    "        #     else:\n",
    "        #         tick_label.set_color('black')\n",
    "                \n",
    "        df[\"population2\"] = df[\"population\"].apply(lambda x: \"biopsy\" if x == \"biopsy\" else \"other\")\n",
    "        min_val = dict()\n",
    "        max_val = dict()\n",
    "        mean_val = dict()\n",
    "\n",
    "        for dist_type in [\"dist_to_root\", \"dist_to_deepest\"]:\n",
    "            min_val[dist_type] = dict()\n",
    "            max_val[dist_type] = dict()\n",
    "            mean_val[dist_type] = dict()\n",
    "            for group in df.population2.unique():\n",
    "                min_val[dist_type][group] = df.groupby(\"population2\")[dist_type].min()[group]\n",
    "                max_val[dist_type][group] = df.groupby(\"population2\")[dist_type].max()[group]\n",
    "                mean_val[dist_type][group] = df.groupby(\"population2\")[dist_type].mean()[group]\n",
    "        df[\"parent_node\"] = df[\"seqid\"].apply(lambda x: treeobj.tree.search_nodes(name=x)[0].up.name)\n",
    "\n",
    "        df[\"parent_node_type\"] = df[\"parent_node\"].apply(lambda x: seqdf[seqdf[\"seqid\"] == x][\"population\"].values[0] if x in seqdf[\"seqid\"].values else \"inferred_node\")\n",
    "\n",
    "        #####------------------------------------------------------------------------------------#####\n",
    "        ##### Calculate Shannon entropy of nodes in a neighborhood of a node\n",
    "        #####------------------------------------------------------------------------------------#####\n",
    "\n",
    "        def calculate_population_entropy_in_neighborhood(input_populations, type = \"global\"):\n",
    "            '''\n",
    "            function to calculate shannon entropy of nodes in the neighborhood of a node.  \n",
    "            '''\n",
    "            countdf = pd.DataFrame(data = input_populations.split(\",\"), columns = [\"population\"]).reset_index()\n",
    "            countdf = countdf.groupby(\"population\")[\"index\"].count().reset_index()\n",
    "            if type == \"global\":\n",
    "                populationdf = pd.DataFrame(data = all_populations, columns = [\"population\"])\n",
    "                populationdf[\"count\"] = populationdf[\"population\"].apply(lambda x: countdf[countdf[\"population\"] == x][\"index\"].values[0] if x in countdf[\"population\"].values else 0)\n",
    "                sum_count = populationdf[\"count\"].sum()\n",
    "                shannon_entropy = -1 * np.sum([(item/sum_count)*(np.log(item/sum_count)) for item in populationdf[\"count\"].values if item != 0])/np.log(len(all_populations))\n",
    "            elif type == \"local\":\n",
    "                sum_count = countdf[\"index\"].sum()\n",
    "                shannon_entropy = -1 * np.sum([(item/sum_count)*(np.log(item/sum_count)) for item in countdf[\"index\"].values if item != 0])/np.log(countdf.shape[0])\n",
    "            else: \n",
    "                raise ValueError(\"type must be either global or local\")\n",
    "            return shannon_entropy\n",
    "        \n",
    "        for dist_cutoff in [3,5,10]:\n",
    "            distdf = pd.DataFrame(df.seqid.unique(), columns = [\"seqid\"])\n",
    "            for seq2 in distdf.seqid.unique():\n",
    "                distdf[seq2] = distdf[\"seqid\"].apply(lambda x: treeobj.tree.get_distance(x, seq2, topology_only= True) if x != seq2 else 0)\n",
    "\n",
    "            all_seqs = [item for item in distdf.columns if item != \"seqid\" and \"seq\" in item]\n",
    "            distdf[f\"neighbor_nodes_{dist_cutoff}\"] = distdf[all_seqs].apply(\n",
    "                lambda x: \",\".join([all_seqs[item] for item in [i for i,j in enumerate(x) if j <= dist_cutoff]]) , axis = 1\n",
    "            )\n",
    "            distdf[f\"neighbor_type{dist_cutoff}\"] = distdf[f\"neighbor_nodes_{dist_cutoff}\"].apply(\n",
    "                lambda x: \",\".join([df[df[\"seqid\"] == item][\"population\"].unique()[0] for item in x.split(\",\")])\n",
    "            )\n",
    "            distdf[f\"shannon_entropy_global_{dist_cutoff}\"] = distdf[f\"neighbor_type{dist_cutoff}\"].apply(\n",
    "                lambda x: calculate_population_entropy_in_neighborhood(x, type = \"global\")\n",
    "            )\n",
    "            distdf[f\"most_frequent_type_{dist_cutoff}\"] = distdf[f\"neighbor_type{dist_cutoff}\"].apply(\n",
    "                lambda x: Counter(x.split(\",\")).most_common(1)[0][0]\n",
    "            )\n",
    "            df = df.merge(distdf[[\"seqid\", \n",
    "                                f\"neighbor_nodes_{dist_cutoff}\", \n",
    "                                f\"neighbor_type{dist_cutoff}\", \n",
    "                                f\"shannon_entropy_global_{dist_cutoff}\", \n",
    "                                f\"most_frequent_type_{dist_cutoff}\"]], \n",
    "                                right_on = \"seqid\", \n",
    "                                left_on = \"seqid\")\n",
    "        #####------------------------------------------------------------------------------------#####\n",
    "        ##### Distance from a node to its furthest child-node\n",
    "        #####------------------------------------------------------------------------------------#####\n",
    "        def get_node_furthest_child(x, topo):\n",
    "            output = treeobj.tree.search_nodes(name=x)[0].get_farthest_leaf(topology_only= topo)\n",
    "            return output[0].name, output[1]\n",
    "        df[['topo_furthest_child_node', 'topo_dist_to_furthest_child_node']] = df['seqid'].apply(\n",
    "            lambda x: pd.Series(\n",
    "                get_node_furthest_child(x, True)))\n",
    "        df[['furthest_child_node', 'dist_to_furthest_child_node']] = df['seqid'].apply(\n",
    "            lambda x: pd.Series(\n",
    "                get_node_furthest_child(x, False)))\n",
    "\n",
    "        #####------------------------------------------------------------------------------------#####\n",
    "        ##### merge to final nodedf dataframe\n",
    "        #####------------------------------------------------------------------------------------#####\n",
    "        nodedf = pd.concat([nodedf, df], axis = 0)\n",
    "    nodedf.to_csv(os.path.join(path_to_08_output, \"nodedf.csv\"), index = False)\n",
    "else:\n",
    "    nodedf = pd.read_csv(os.path.join(path_to_08_output, \"nodedf.csv\"))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ete3_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
