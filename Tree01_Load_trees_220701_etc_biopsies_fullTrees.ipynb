{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from typing import List, Union, Optional, Callable\n",
    "import pickle\n",
    "from Bio import AlignIO, SeqIO\n",
    "from ete3 import Tree, TreeNode\n",
    "from gctree import CollapsedTree\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import umap\n",
    "from ete3 import Tree, faces, TreeStyle, NodeStyle, TextFace, SequenceFace, COLOR_SCHEMES, CircleFace\n",
    "from GCTree_preparation import *\n",
    "import warnings\n",
    "import math\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "path_to_storage = \"/media/hieunguyen/HNSD01/storage/all_BSimons_datasets\"\n",
    "outdir = \"/media/hieunguyen/GSHD_HN01/outdir/sc_bulk_BCR_data_analysis_v0.1\"\n",
    "\n",
    "PROJECT = \"220701_etc_biopsies\"\n",
    "path_to_main_output = f\"{outdir}/tree_analysis/{PROJECT}\"\n",
    "path_to_01_output = os.path.join(path_to_main_output, \"01_output\")\n",
    "os.system(f\"mkdir -p {path_to_01_output}\")\n",
    "\n",
    "output_type = \"mouse_based_output\"\n",
    "\n",
    "path_to_trees = os.path.join(path_to_storage, PROJECT, \"GCtrees/v0.2\", output_type)\n",
    "\n",
    "all_tree_folder = [item for item in pathlib.Path(path_to_trees).glob(\"*\") if \n",
    "                   os.path.isfile(f\"{str(item)}/02_dnapars/gctree.out.inference.1.nk\") == True]\n",
    "\n",
    "all_nk_files = [item for item in pathlib.Path(path_to_trees).glob(\"*/*/*gctree.out.inference.1.nk\")]  \n",
    "print(f\"Number of trees: {len(all_tree_folder)}\")   \n",
    "\n",
    "path_to_metadata = \"/media/hieunguyen/HNSD01/src/sc_bulk_BCR_data_analysis/preprocessing/220701_etc_biopsies/metadata.csv\"\n",
    "mid_metadata = pd.read_csv(path_to_metadata, sep =\";\")\n",
    "\n",
    "##### Re run the summary analysis of all trees and rendering tree figures\n",
    "# rerun = True\n",
    "rerun = False\n",
    "\n",
    "path_to_04_output = os.path.join(outdir, \"VDJ_output\", \"04_output\")\n",
    "thres = 0.85\n",
    "\n",
    "clonedf = pd.read_csv(os.path.join(path_to_04_output, \"full_clonedf_with_mutation_rate.csv\"), index_col= [0])\n",
    "clonedf = clonedf[clonedf['num_mutation'] != \"region_not_covered-skip\"]\n",
    "clonedf = clonedf[clonedf['dataset.name'] == \"220701_etc_biopsies\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if (os.path.isfile(f\"{path_to_01_output}/tree_summarydf.csv\") == False) or (rerun == True):\n",
    "    saveTreeobj = dict()\n",
    "    # loop through all trees\n",
    "    maindf = pd.DataFrame()\n",
    "    # for treedir in tqdm(all_tree_folder[0:1]):\n",
    "    for treedir in tqdm(all_tree_folder):\n",
    "        cloneid = treedir.name\n",
    "        treedir = str(treedir)\n",
    "\n",
    "        mouseID = cloneid.split(\"_\")[0]\n",
    "        V_gene = cloneid.split(\"_\")[1]\n",
    "        J_gene = cloneid.split(\"_\")[2]\n",
    "        CDR3_len = cloneid.split(\"_\")[3]\n",
    "\n",
    "        nk_path = f\"{treedir}/02_dnapars/gctree.out.inference.1.nk\"\n",
    "        ab_dict_path = os.path.join(treedir, \"01_deduplicate\", f\"{cloneid}.abundance.csv\")\n",
    "        path_to_orig_fasta= f\"{treedir}/01_deduplicate/{cloneid}.fasta\"\n",
    "        input_idmaps = f\"{treedir}/01_deduplicate/{cloneid}.id_map_seq.csv\"\n",
    "    \n",
    "        treeobj = GCtree(\n",
    "            nk_path = nk_path,\n",
    "            ab_dict_path = ab_dict_path,\n",
    "            origin_fasta = path_to_orig_fasta,\n",
    "            idmap_seq = input_idmaps\n",
    "        )\n",
    "        \n",
    "        saveTreeobj[cloneid] = treeobj\n",
    "        seqdf_orig = treeobj.seqdf\n",
    "        seqs = treeobj.seqs\n",
    "        num_nodes = len(treeobj.nodes)\n",
    "        num_leaves = len(treeobj.leaves)\n",
    "        num_internal_nodes = len(treeobj.internal_nodes)\n",
    "        num_passthrough_nodes = len(treeobj.passthrough_nodes)\n",
    "        num_split_nodes = len(treeobj.split_nodes)\n",
    "        num_observed_nodes = len(treeobj.observed_nodes)\n",
    "        num_inferred_nodes = len(treeobj.inferred_nodes)\n",
    "        count_single_node = treeobj.count_single_node\n",
    "        count_mix_node = treeobj.count_mix_node\n",
    "        all_MIDs = seqdf_orig[\"MID\"].unique()\n",
    "        all_groups = [mid_metadata[mid_metadata[\"Unnamed: 0\"] == item][\"population\"].unique()[0] for item in all_MIDs]\n",
    "        tmpdf = pd.DataFrame(\n",
    "            {\n",
    "                \"cloneid\": cloneid,\n",
    "                \"mouseID\": mouseID,\n",
    "                \"V_gene\": V_gene,\n",
    "                \"J_gene\": J_gene,\n",
    "                \"CDR3_len\": CDR3_len,\n",
    "                \"num_nodes\": num_nodes,\n",
    "                \"num_leaves\": num_leaves,\n",
    "                \"num_internal_nodes\": num_internal_nodes,\n",
    "                \"num_passthrough_nodes\": num_passthrough_nodes,\n",
    "                \"num_split_nodes\": num_split_nodes,\n",
    "                \"num_observed_nodes\": num_observed_nodes,\n",
    "                \"num_inferred_nodes\": num_inferred_nodes,\n",
    "                \"num_MID\": len(all_MIDs),\n",
    "                \"available_population\": \",\".join(all_groups),\n",
    "                \"num_seq_fasta\": len(seqs),\n",
    "                \"num_single_node\": count_single_node,\n",
    "                \"num_mix_node\": count_mix_node\n",
    "            },\n",
    "            index=[0],\n",
    "        )\n",
    "        maindf = pd.concat([maindf, tmpdf], axis = 0)\n",
    "    maindf = maindf.sort_values(by = \"num_MID\", ascending = False)\n",
    "    maindf[\"check_QC_tree\"] = maindf[\"cloneid\"].apply(lambda x: \"CDR3 region not covered\" if \"region_not_cover\" in saveTreeobj[x].seqdf.ID.values[0] else \"pass\")\n",
    "    maindf.to_csv(f\"{path_to_01_output}/tree_summarydf.csv\", index = False)\n",
    "    with open(f\"{path_to_01_output}/saveTreeobj.pkl\", \"wb\") as f:\n",
    "        pickle.dump(saveTreeobj, f)\n",
    "else:\n",
    "    maindf = pd.read_csv(f\"{path_to_01_output}/tree_summarydf.csv\")\n",
    "    # Reload the dictionary from the pickle file\n",
    "    with open(f\"{path_to_01_output}/saveTreeobj.pkl\", \"rb\") as f:\n",
    "        saveTreeobj = pickle.load(f)\n",
    "\n",
    "color_path = \"./hex_color.csv\"\n",
    "mid_metadata.columns = ['MID', 'mouse', 'age', 'day', 'population', 'label',\n",
    "       'Unnamed: 6', 'Unnamed: 7', 'hex color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (os.path.isfile(f\"{path_to_01_output}/finished_tree_rendering.csv\") == False) or (rerun == True):\n",
    "    for cloneid in tqdm(saveTreeobj.keys()):\n",
    "        mouseid = cloneid.split(\"_\")[0]\n",
    "        path_to_save_tree_svg = os.path.join(path_to_01_output, mouseid)\n",
    "        os.system(f\"mkdir -p {path_to_save_tree_svg}\")\n",
    "\n",
    "        treeobj = saveTreeobj[cloneid] \n",
    "        avai_mids = treeobj.seqdf[\"MID\"].unique()\n",
    "        mid_color_pal = pd.read_csv(color_path, index_col = [0]).to_dict()[\"hex color\"]\n",
    "\n",
    "        ts = treeobj.generate_tree_style(color_path = color_path)\n",
    "        # treeobj.tree.render(\"%%inline\", tree_style=ts) \n",
    "\n",
    "        for input_mid in avai_mids:\n",
    "            if input_mid == \"GL\":\n",
    "                input_mid_col = \"gray\"\n",
    "            else:\n",
    "                input_mid_col = mid_color_pal[input_mid]\n",
    "            ts.legend.add_face(CircleFace(10, input_mid_col), column = 0)\n",
    "            ts.legend.add_face(TextFace(input_mid), column = 0)\n",
    "\n",
    "        _ = treeobj.tree.render(f\"{path_to_save_tree_svg}/{cloneid}.svg\", tree_style=ts) \n",
    "    pd.DataFrame(data = [\"finished_tree_rendering\"]).to_csv(f\"{path_to_01_output}/finished_tree_rendering.csv\", index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_node_df = maindf[\n",
    "    (maindf[\"num_mix_node\"] > 0) & \n",
    "    (maindf[\"check_QC_tree\"] == \"pass\") & \n",
    "    (maindf[\"available_population\"].str.contains(\"biopsy\"))].sort_values(by = \"num_mix_node\", ascending = False)\n",
    "mixed_node_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### analysis example for 1 tree. \n",
    "cloneid = \"m30_IGHV1-82-01_IGHJ2-01_30_1.aln\"\n",
    "\n",
    "mouseid = cloneid.split(\"_\")[0]\n",
    "path_to_save_tree_svg = os.path.join(path_to_01_output, mouseid)\n",
    "os.system(f\"mkdir -p {path_to_save_tree_svg}\")\n",
    "\n",
    "treeobj = saveTreeobj[cloneid] \n",
    "avai_mids = treeobj.seqdf[\"MID\"].unique()\n",
    "mid_color_pal = pd.read_csv(color_path, index_col = [0]).to_dict()[\"hex color\"]\n",
    "\n",
    "ts = treeobj.generate_tree_style(color_path = color_path)\n",
    "# treeobj.tree.render(\"%%inline\", tree_style=ts) \n",
    "\n",
    "for input_mid in avai_mids:\n",
    "    if input_mid == \"GL\":\n",
    "        input_mid_col = \"gray\"\n",
    "    else:\n",
    "        input_mid_col = mid_color_pal[input_mid]\n",
    "    ts.legend.add_face(CircleFace(10, input_mid_col), column = 0)\n",
    "    ts.legend.add_face(TextFace(input_mid), column = 0)\n",
    "\n",
    "idmapdf = treeobj.idmapseqdf.copy()\n",
    "seqdf = treeobj.seqdf.copy()\n",
    "seqdf[\"population\"] = seqdf[\"MID\"].apply(lambda x: mid_metadata[mid_metadata[\"MID\"] == x][\"population\"].values[0])\n",
    "seqdf = seqdf.merge(idmapdf, right_on = \"seq\", left_on = \"seq\")\n",
    "treeobj.tree.render(f\"%%inline\", tree_style=ts) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add distance information to all trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerun = False\n",
    "if os.path.isfile(os.path.join(path_to_01_output, \"distdf.csv\")) == False or rerun == True:\n",
    "    distdf = pd.DataFrame()\n",
    "    for cloneid in tqdm(list(saveTreeobj.keys())):\n",
    "        treeobj = saveTreeobj[cloneid]\n",
    "        seqdf = treeobj.seqdf.copy()\n",
    "        idmapdf = treeobj.idmapseqdf.copy()\n",
    "        seqdf[\"CDR3nt\"] = seqdf[\"ID\"].apply(lambda x: x.split(\"|\")[3].split(\":\")[1])\n",
    "        seqdf[\"CDR3aa\"] = seqdf[\"ID\"].apply(lambda x: x.split(\"|\")[2].split(\":\")[1])\n",
    "        seqdf = seqdf.merge(idmapdf, right_on = \"seq\", left_on = \"seq\")\n",
    "\n",
    "        df = pd.DataFrame(data = seqdf.seqid.unique(), columns = [\"seqid\"])\n",
    "        df[\"MID\"] = df[\"seqid\"].apply(lambda x: \"_\".join(seqdf[seqdf[\"seqid\"] == x][\"MID\"].values))\n",
    "        df[\"mouseid\"] = cloneid.split(\"_\")[0]\n",
    "        df[\"cloneID\"] = cloneid\n",
    "        df[\"CDR3nt\"] = df[\"seqid\"].apply(lambda x: seqdf[seqdf[\"seqid\"] == x][\"CDR3nt\"].values[0])\n",
    "        df[\"CDR3aa\"] = df[\"seqid\"].apply(lambda x: seqdf[seqdf[\"seqid\"] == x][\"CDR3aa\"].values[0])\n",
    "\n",
    "        df[\"dist_to_root\"] = df[\"seqid\"].apply(lambda x: treeobj.node_depth(node = [item for item in treeobj.nodes if item.name == x][0], topo = False))\n",
    "        df[\"topo_dist_to_root\"] = df[\"seqid\"].apply(lambda x: treeobj.node_depth(node = [item for item in treeobj.nodes if item.name == x][0], topo = True))\n",
    "\n",
    "        deepest_node = df[df[\"dist_to_root\"] == df[\"dist_to_root\"].max()].seqid.unique()[0]\n",
    "\n",
    "        df[\"dist_to_deepest\"] = df[\"seqid\"].apply(lambda x: treeobj.tree.get_distance(x, deepest_node) if x != deepest_node else 0)\n",
    "        df[\"topo_dist_to_deepest\"] = df[\"seqid\"].apply(lambda x: treeobj.tree.get_distance(x, deepest_node, topology_only= True) if x != deepest_node else 0)\n",
    "\n",
    "        # function definition\n",
    "        def get_node_furthest_child(x, topo):\n",
    "            'Function to get the furthest child node of a given node and the distance to it'\n",
    "            output = treeobj.tree.search_nodes(name=x)[0].get_farthest_leaf(topology_only= topo)\n",
    "            return output[0].name, output[1]\n",
    "\n",
    "        df[['topo_furthest_child_node', 'topo_dist_to_furthest_child_node']] = df['seqid'].apply(\n",
    "            lambda x: pd.Series(\n",
    "                get_node_furthest_child(x, True)))\n",
    "        df[['furthest_child_node', 'dist_to_furthest_child_node']] = df['seqid'].apply(\n",
    "            lambda x: pd.Series(\n",
    "                get_node_furthest_child(x, False)))\n",
    "\n",
    "        change_name = {\n",
    "            \"dist_to_root\": \"rootness\",\n",
    "            \"topo_dist_to_root\": \"topo_rootness\",\n",
    "            \"dist_to_furthest_child_node\": \"leafness\",\n",
    "            \"topo_dist_to_furthest_child_node\": \"topo_leafness\"\n",
    "        }\n",
    "\n",
    "        df.columns = [change_name[item] if item in change_name.keys() else item for item in df.columns]\n",
    "        df[\"num_node\"] = len(treeobj.nodes)\n",
    "        df[\"num_leaves\"] = len(treeobj.leaves)\n",
    "\n",
    "        distdf = pd.concat([distdf, df], axis = 0)\n",
    "    distdf[\"sample_type\"] = distdf[\"MID\"].apply(lambda x: \"_\".join(mid_metadata[mid_metadata[\"MID\"].isin(x.split(\"_\"))][\"population\"].values) \\\n",
    "                                                               if \"_\" in x else mid_metadata[mid_metadata[\"MID\"] == x][\"population\"].values[0])\n",
    "    distdf[\"mix_node\"] = distdf[\"sample_type\"].apply(lambda x: \"yes\" if \"_\" in x else \"no\")\n",
    "    distdf.to_csv(os.path.join(path_to_01_output, f\"{PROJECT}_distdf.csv\"), index = False)\n",
    "else:\n",
    "    print(\"reading in distance data frame ...\")\n",
    "    distdf = pd.read_csv(os.path.join(path_to_01_output, f\"{PROJECT}_distdf.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "public_clonedf = pd.read_csv(\"public_clones.csv\")\n",
    "distdf[\"V_gene\"] = distdf[\"cloneID\"].apply(lambda x: \"-\".join(x.split(\"_\")[1].split(\"-\")[0:2]))\n",
    "distdf[\"J_gene\"] = distdf[\"cloneID\"].apply(lambda x: \"-\".join(x.split(\"_\")[2].split(\"-\")[0:1]))\n",
    "\n",
    "match_public_clonedf = pd.DataFrame()\n",
    "for i in range(public_clonedf.shape[0]):\n",
    "    v_gene = public_clonedf.iloc[i][\"V_gene\"]\n",
    "    j_gene = public_clonedf.iloc[i][\"J_gene\"]\n",
    "    public_sequence = public_clonedf.iloc[i][\"aaseq\"]\n",
    "    tmpdf = distdf[(distdf[\"V_gene\"] == v_gene) & (distdf[\"J_gene\"] == j_gene)]\n",
    "    tmpdf[\"public_CDR3nt\"] = public_sequence\n",
    "    match_public_clonedf = pd.concat([match_public_clonedf, tmpdf], axis = 0)\n",
    "\n",
    "match_public_clonedf[\"truncated_CDR3aa\"] = match_public_clonedf[\"CDR3aa\"].apply(lambda x: x[1:-1])\n",
    "match_public_clonedf[\"num_diff_public_clone\"] = match_public_clonedf[[\"truncated_CDR3aa\", \"public_CDR3nt\"]].apply(lambda x: nltk.edit_distance(x[0], x[1]), axis = 1)\n",
    "match_public_clonedf[\"dist_to_public_clone\"] = match_public_clonedf[[\"truncated_CDR3aa\", \"public_CDR3nt\"]].apply(lambda x: nltk.edit_distance(x[0], x[1])/min(len(x[0]), len(x[1])), axis = 1)\n",
    "\n",
    "match_public_clonedf.to_csv(os.path.join(path_to_01_output, \"match_public_clonedf.csv\"), index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for f in [ 'rootness',\n",
    "#        'topo_rootness', 'dist_to_deepest', 'topo_dist_to_deepest',\n",
    "#        'topo_furthest_child_node', 'topo_leafness']:\n",
    "#     plotdf = distdf[[\"num_node\", \"cloneID\", \"sample_type\", f]].copy()\n",
    "#     plotdf[\"sample_type\"] = plotdf[\"sample_type\"].apply(lambda x: x.split(\"_\")[0])\n",
    "#     plotdf[\"mouseID\"] = plotdf[\"cloneID\"].apply(lambda x: x.split(\"_\")[0])\n",
    "#     plotdf = plotdf.explode(\"sample_type\")\n",
    "\n",
    "#     plotdf[\"sample_type\"] = plotdf[\"sample_type\"].apply(lambda x: \"biopsy\" if x == \"biopsy\" else x.replace(\"Ly6c+\", \"\").replace(\"Ly6c-\", \"\"))\n",
    "#     plotdf = plotdf.sort_values(by = [\"mouseID\", \"num_node\", \"cloneID\", \"sample_type\"], ascending = [True, False, False, True])\n",
    "#     # plotdf.to_excel(os.path.join(path_to_01_output, f\"plotdf_{PROJECT}.xlsx\"), index = False)\n",
    "\n",
    "#     for mouseid in plotdf.mouseID.unique():\n",
    "#         for sampletype in [\"YFP+\", \"YFP-\", \"biopsy\"]:\n",
    "#             os.system(\"mkdir -p {}\".format(os.path.join(path_to_01_output, \"prism_plots\", mouseid)))\n",
    "\n",
    "#             all_ranked_clones = plotdf[(plotdf[\"mouseID\"] == mouseid) & (plotdf[\"sample_type\"] == sampletype)].cloneID.unique()\n",
    "#             prism_plotdf = pd.DataFrame()\n",
    "\n",
    "#             for cloneid in tqdm(all_ranked_clones):\n",
    "#                 tmpdf =  pd.DataFrame(data = plotdf[plotdf[\"cloneID\"] == cloneid][f].values).T\n",
    "#                 prism_plotdf = pd.concat([prism_plotdf, tmpdf], axis=0)\n",
    "\n",
    "#             prism_plotdf.reset_index().drop(\"index\", axis = 1).to_excel(os.path.join(path_to_01_output, \"prism_plots\", mouseid, f\"{sampletype}_{f}.xlsx\"), index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ete3_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
